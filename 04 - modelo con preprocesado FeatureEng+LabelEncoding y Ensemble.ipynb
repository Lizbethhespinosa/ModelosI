{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lizbethhespinosa/ModelosI/blob/main/04%20-%20modelo%20con%20preprocesado%20FeatureEng%2BLabelEncoding%20y%20Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consideraciones antes de ejecutar el notebook\n"
      ],
      "metadata": {
        "id": "FnA_N-eQY2ZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se debe cambiar el entorno de ejecuciÃ³n para que el programa corra de manera correcta: clic en entorno de ejecucion -> cambiar tipo de entorno de ejecuciÃ³n -> se selecciona GPU T4 -> guardar.\n",
        "\n",
        "* **Preprocesado FeatureEng:** porque realizamos IngenierÃ­a de CaracterÃ­sticas (Feature Engineering) al crear manualmente la variable SCORE_PRIVILEGIOS sumando los lujos. Esto no estaba en los datos originales.\n",
        "\n",
        "* **LabelEncoding:** porque para poder meter los datos a los 3 modelos a la vez, convertimos todo el texto a nÃºmeros enteros (0, 1, 2...) usando LabelEncoder. (Si hubiÃ©ramos usado OneHot o Nativo, XGBoost o LightGBM habrÃ­an fallado o tardado mÃ¡s).\n",
        "\n",
        "* **Ensemble:** porque la tÃ©cnica de modelado no es un algoritmo individual, sino un Ensamble de VotaciÃ³n (Voting) que promedia las probabilidades de tres \"cerebros\" distintos, los cuales son Catboost, XGBoosty ligtGBM."
      ],
      "metadata": {
        "id": "0Coe_w_0YzYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalacion\n"
      ],
      "metadata": {
        "id": "yVWLdBhuOw51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos las 3 librerÃ­as de potencia\n",
        "!pip install catboost xgboost lightgbm -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurar Kaggle\n",
        "data = {\"username\":\"lizbethhespinosa\",\"key\":\"07b7534e53b0fe2b8ec81ed287410d9e\"}\n",
        "with open('kaggle.json','w') as f: json.dump(data, f)\n",
        "!chmod 600 kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "print(\"ğŸ“¥ Descargando datos...\")\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia -p /content/ --force\n",
        "!unzip -o -q udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
        "print(\"âœ… Entorno listo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geYlzw3-O1QH",
        "outputId": "5fc2ff98-0c4c-4e4c-c0bd-ffc8f9f1659a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hğŸ“¥ Descargando datos...\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "100% 29.9M/29.9M [00:00<00:00, 1.31GB/s]\n",
            "âœ… Entorno listo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento Unificado (Label Encoding)"
      ],
      "metadata": {
        "id": "usSkgTsDO5_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "TARGET_COL = 'RENDIMIENTO_GLOBAL'\n",
        "ID_COL = 'ID'\n",
        "\n",
        "# Unir para Feature Engineering\n",
        "df_all = pd.concat([df_train.drop(columns=[TARGET_COL]), df_test], axis=0)\n",
        "\n",
        "# --- 1. FEATURE ENGINEERING (Las variables nuevas) ---\n",
        "cols_tiene = [c for c in df_all.columns if 'TIENE' in c]\n",
        "for col in cols_tiene:\n",
        "    df_all[col] = df_all[col].astype(str).str.lower().map({'si': 1, 'yes': 1, 'no': 0}).fillna(0)\n",
        "df_all['SCORE_PRIVILEGIOS'] = df_all[cols_tiene].sum(axis=1)\n",
        "\n",
        "# --- 2. CODIFICACIÃ“N NUMÃ‰RICA (LABEL ENCODING) ---\n",
        "# XGBoost y LightGBM odian el texto. Convertimos todo a nÃºmeros.\n",
        "categorical_cols = df_all.select_dtypes(include=['object']).columns.tolist()\n",
        "if ID_COL in categorical_cols: categorical_cols.remove(ID_COL)\n",
        "\n",
        "print(\"âš™ï¸ Convirtiendo texto a nÃºmeros...\")\n",
        "for col in categorical_cols:\n",
        "    df_all[col] = df_all[col].fillna(\"Missing\").astype(str)\n",
        "    le = LabelEncoder()\n",
        "    df_all[col] = le.fit_transform(df_all[col])\n",
        "\n",
        "# Rellenar numÃ©ricos restantes\n",
        "numeric_cols = df_all.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "for col in numeric_cols:\n",
        "    df_all[col] = df_all[col].fillna(-999)\n",
        "\n",
        "# Separar\n",
        "X = df_all.iloc[:len(df_train)].drop(columns=[ID_COL], errors='ignore')\n",
        "X_test_final = df_all.iloc[len(df_train):].drop(columns=[ID_COL], errors='ignore')\n",
        "y = df_train[TARGET_COL]\n",
        "\n",
        "# Codificar Target tambiÃ©n\n",
        "le_target = LabelEncoder()\n",
        "y_encoded = le_target.fit_transform(y)\n",
        "\n",
        "print(f\"âœ… Datos listos. Clases: {le_target.classes_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9_YWhYfO870",
        "outputId": "69788f17-4b7c-4d99-fdfd-256d3086505e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš™ï¸ Convirtiendo texto a nÃºmeros...\n",
            "âœ… Datos listos. Clases: ['alto' 'bajo' 'medio-alto' 'medio-bajo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo 1 - CatBoost (GPU)"
      ],
      "metadata": {
        "id": "6hlI5eHXO_ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReinstalaciÃ³n rÃ¡pida para evitar el error de CUDA driver\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos (Usamos stratify para mantener proporciones)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "\n",
        "print(\"ğŸ¯ Entrenando Modelo 1: CatBoost (Modo GPU)...\")\n",
        "\n",
        "model_cat = CatBoostClassifier(\n",
        "    iterations=2500,\n",
        "    learning_rate=0.04,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=5,\n",
        "\n",
        "    # --- CONFIGURACIÃ“N GPU ---\n",
        "    task_type=\"GPU\",\n",
        "    devices='0',\n",
        "    # -------------------------\n",
        "\n",
        "    # Nota: No ponemos 'cat_features' aquÃ­ porque en el Ensamble\n",
        "    # ya convertimos todo a nÃºmeros (LabelEncoding) en la celda 2.\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='Accuracy',\n",
        "    random_seed=42,\n",
        "    verbose=500,\n",
        "    early_stopping_rounds=200\n",
        ")\n",
        "\n",
        "model_cat.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    use_best_model=True\n",
        ")\n",
        "\n",
        "# Guardamos PROBABILIDADES para el ensamble\n",
        "probs_cat = model_cat.predict_proba(X_test_final)\n",
        "print(\"âœ… CatBoost terminado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNKdgixkPCli",
        "outputId": "914727ff-eef3-4ed7-ec7a-915184b9a395"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Entrenando Modelo 1: CatBoost (Modo GPU)...\n",
            "0:\tlearn: 0.3802166\ttest: 0.3801588\tbest: 0.3801588 (0)\ttotal: 158ms\tremaining: 6m 35s\n",
            "500:\tlearn: 0.4377133\ttest: 0.4293526\tbest: 0.4293815 (490)\ttotal: 16.5s\tremaining: 1m 5s\n",
            "1000:\tlearn: 0.4529471\ttest: 0.4323562\tbest: 0.4327413 (944)\ttotal: 27.9s\tremaining: 41.7s\n",
            "1500:\tlearn: 0.4653829\ttest: 0.4332034\tbest: 0.4336462 (1420)\ttotal: 39.2s\tremaining: 26.1s\n",
            "bestTest = 0.4337424789\n",
            "bestIteration = 1536\n",
            "Shrink model to first 1537 iterations.\n",
            "âœ… CatBoost terminado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo 2 - XGBoost (GPU)"
      ],
      "metadata": {
        "id": "M2EerS0PPEOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"ğŸš€ Entrenando Modelo 2: XGBoost (Modo GPU)...\")\n",
        "\n",
        "model_xgb = XGBClassifier(\n",
        "    n_estimators=2500,    # Subimos iteraciones para igualar potencia\n",
        "    learning_rate=0.04,\n",
        "    max_depth=8,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "\n",
        "    # --- CONFIGURACIÃ“N GPU ---\n",
        "    tree_method='hist',   # MÃ©todo histograma (el mÃ¡s rÃ¡pido)\n",
        "    device='cuda',        # Usar la GPU de Colab\n",
        "    # -------------------------\n",
        "\n",
        "    random_state=42,\n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_xgb.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=500\n",
        ")\n",
        "\n",
        "probs_xgb = model_xgb.predict_proba(X_test_final)\n",
        "print(\"âœ… XGBoost terminado.\")"
      ],
      "metadata": {
        "id": "B4DNV_2aPGuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ed5cb0-a32d-4046-d67e-39b3ea925812"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Entrenando Modelo 2: XGBoost (Modo GPU)...\n",
            "[0]\tvalidation_0-mlogloss:1.37980\n",
            "[500]\tvalidation_0-mlogloss:1.20014\n",
            "[902]\tvalidation_0-mlogloss:1.19912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [13:35:00] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… XGBoost terminado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo 3 - LightGBM (CPU Optimizado)"
      ],
      "metadata": {
        "id": "i8FZchAaPJu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "print(\"ğŸ’¡ Entrenando Modelo 3: LightGBM...\")\n",
        "model_lgb = LGBMClassifier(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31, # TÃ­pico de LightGBM\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_lgb.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric='multi_logloss',\n",
        "    callbacks=[\n",
        "        # LightGBM usa callbacks para verbose en versiones nuevas,\n",
        "        # si falla, simplemente quita el argumento callbacks\n",
        "    ]\n",
        ")\n",
        "\n",
        "probs_lgb = model_lgb.predict_proba(X_test_final)\n",
        "print(\"âœ… LightGBM terminado.\")"
      ],
      "metadata": {
        "id": "ozfRNsSWPLDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516c4623-6b77-44de-ce23-c782d92dc9ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¡ Entrenando Modelo 3: LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144820 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1238\n",
            "[LightGBM] [Info] Number of data points in the train set: 588625, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.371992\n",
            "[LightGBM] [Info] Start training from score -1.387091\n",
            "[LightGBM] [Info] Start training from score -1.395032\n",
            "[LightGBM] [Info] Start training from score -1.391214\n",
            "âœ… LightGBM terminado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EL ENSAMBLE (Soft Voting)"
      ],
      "metadata": {
        "id": "CytyTK8KPOML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"âš–ï¸ Calculando el Ensamble (Promedio Ponderado)...\")\n",
        "\n",
        "# Podemos dar pesos. CatBoost y XGBoost suelen ser mejores, les damos mÃ¡s peso.\n",
        "# Pesos: CatBoost (40%) + XGBoost (40%) + LightGBM (20%)\n",
        "final_probs = (probs_cat * 0.4) + (probs_xgb * 0.4) + (probs_lgb * 0.2)\n",
        "\n",
        "# Elegimos la clase con mayor probabilidad promedio\n",
        "final_preds_indices = np.argmax(final_probs, axis=1)\n",
        "final_preds_texto = le_target.inverse_transform(final_preds_indices)\n",
        "\n",
        "# Crear archivo\n",
        "if ID_COL in df_test.columns:\n",
        "    test_ids = df_test[ID_COL]\n",
        "else:\n",
        "    test_ids = df_test.index\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test_ids,\n",
        "    TARGET_COL: final_preds_texto\n",
        "})\n",
        "\n",
        "out_filename = \"submission_07_Ensemble_Voting.csv\"\n",
        "submission.to_csv(out_filename, index=False)\n",
        "print(f\"ğŸ’¾ Archivo Final Generado: {out_filename}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vy7nSMfHPQPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880a18ba-d9fe-4157-a359-928b774dff0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš–ï¸ Calculando el Ensamble (Promedio Ponderado)...\n",
            "ğŸ’¾ Archivo Final Generado: submission_07_Ensemble_Voting.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Subir\n"
      ],
      "metadata": {
        "id": "hejVvJSLPWyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"Notebook 07 - Ensemble (CatBoost + XGBoost + LightGBM)\"\n",
        "!kaggle competitions submit -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia -f {out_filename} -m \"{message}\"\n",
        "\n",
        "print(\"ğŸ† Â¡Subida lista! Este deberÃ­a ser tu mejor puntaje.\")"
      ],
      "metadata": {
        "id": "GTia8H-iPYL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e97041-aaa9-4cf7-f6ab-47056112c428"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4.04M/4.04M [00:03<00:00, 1.29MB/s]\n",
            "Successfully submitted to UDEA/ai4eng 20252 - Pruebas Saber Pro ColombiağŸ† Â¡Subida lista! Este deberÃ­a ser tu mejor puntaje.\n"
          ]
        }
      ]
    }
  ]
}